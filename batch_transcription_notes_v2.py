#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ‰¹æ¬¡è™•ç†éŸ³é »è½‰éŒ„æ–‡ä»¶ï¼Œç”Ÿæˆè©³ç´°ç­†è¨˜
ä½¿ç”¨ Gemini API é€²è¡Œå…§å®¹æ•´ç†å’Œæ½¤ç¨¿
"""

import os
import sys
import json
import time
import re
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
import google.generativeai as genai
from datetime import datetime


def setup_gemini(api_key: str):
    """è¨­ç½® Gemini API"""
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-2.5-pro')
    return model


def read_transcription_file(file_path: str) -> str:
    """è®€å–è½‰éŒ„æ–‡ä»¶"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # å¦‚æœæ˜¯ SRT æ–‡ä»¶ï¼Œå»é™¤æ™‚é–“æˆ³
    if file_path.endswith('.srt'):
        # ç§»é™¤ SRT æ ¼å¼çš„åºè™Ÿå’Œæ™‚é–“æˆ³
        lines = content.split('\n')
        text_lines = []
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            # è·³éåºè™Ÿ
            if line.isdigit():
                i += 1
                # è·³éæ™‚é–“æˆ³
                if i < len(lines) and '-->' in lines[i]:
                    i += 1
                # æ”¶é›†æ–‡æœ¬
                while i < len(lines) and lines[i].strip() != '':
                    text_lines.append(lines[i].strip())
                    i += 1
            i += 1
        content = ' '.join(text_lines)
    
    return content


def find_agenda_file(folder_path: str, session_name: str) -> Optional[str]:
    """æŸ¥æ‰¾è­°ç¨‹æ–‡ä»¶ - åŒåçš„ RTF æˆ–å…¶ä»–æ ¼å¼æ–‡ä»¶"""
    folder = Path(folder_path)
    
    # å¾æœƒè­°åç¨±ä¸­æå–åŸºæœ¬åç¨±ï¼ˆå»é™¤æ“´å±•åï¼‰
    base_name = session_name
    if '.' in base_name:
        base_name = base_name.rsplit('.', 1)[0]
    
    # æŸ¥æ‰¾åŒåçš„å…¶ä»–æ ¼å¼æ–‡ä»¶
    for ext in ['.rtfd', '.rtf', '.docx', '.doc', '.txt']:
        # å˜—è©¦ä¸åŒçš„æ–‡ä»¶åæ¨¡å¼
        patterns = [
            f"{base_name}{ext}",
            f"{base_name.replace('transcription-', '')}{ext}",  # å¦‚æœæ˜¯ transcription-Xï¼Œå˜—è©¦åªç”¨ X
            f"{folder.name}{ext}"  # å˜—è©¦ç”¨æ–‡ä»¶å¤¾åç¨±
        ]
        
        for pattern in patterns:
            agenda_file = folder / pattern
            if agenda_file.exists() and not agenda_file.name.startswith('._'):
                return str(agenda_file)
    
    # å¦‚æœæ‰¾ä¸åˆ°åŒåæ–‡ä»¶ï¼ŒæŸ¥æ‰¾ä»»ä½•è­°ç¨‹æ–‡ä»¶
    for ext in ['*.rtfd', '*.rtf', '*.docx', '*.doc']:
        files = list(folder.glob(ext))
        for f in files:
            if not f.name.startswith('._') and 'transcription' not in f.name.lower():
                return str(f)
    
    return None


def extract_agenda_from_file(file_path: str) -> str:
    """å¾æ–‡ä»¶ä¸­æå–è­°ç¨‹ä¿¡æ¯"""
    try:
        if file_path.endswith('.txt'):
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()[:3000]  # å¢åŠ é•·åº¦
                
        elif file_path.endswith('.rtf'):
            # ç°¡å–®æå– RTF ä¸­çš„æ–‡æœ¬
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                # ç§»é™¤ RTF æ§åˆ¶å­—ç¬¦ä½†ä¿ç•™åŸºæœ¬æ ¼å¼
                text = re.sub(r'\\par\s*', '\n', content)  # æ®µè½
                text = re.sub(r'\\tab\s*', '\t', text)     # è£½è¡¨ç¬¦
                text = re.sub(r'\\[a-z]+\d*\s?', '', text) # å…¶ä»–æ§åˆ¶å­—ç¬¦
                text = re.sub(r'[{}]', '', text)
                return text[:3000]
                
        elif file_path.endswith('.rtfd'):
            # RTFD æ˜¯ä¸€å€‹æ–‡ä»¶å¤¾ï¼ŒåŒ…å« RTF æ–‡ä»¶
            rtfd_path = Path(file_path)
            if rtfd_path.is_dir():
                rtf_file = rtfd_path / 'TXT.rtf'
                if rtf_file.exists():
                    return extract_agenda_from_file(str(rtf_file))
                    
        elif file_path.endswith('.docx'):
            # å¦‚æœæœ‰ python-docx å¯ä»¥ä½¿ç”¨
            try:
                import docx
                doc = docx.Document(file_path)
                text = '\n'.join([para.text for para in doc.paragraphs])
                return text[:3000]
            except:
                return "Agenda file found but cannot read .docx format"
                
    except Exception as e:
        return f"Error reading agenda: {str(e)}"
    
    return "No agenda content extracted"


def process_transcription_with_gemini(
    model,
    transcription_content: str,
    agenda_content: Optional[str],
    session_title: str
) -> Tuple[bool, str, Dict[str, Any]]:
    """ä½¿ç”¨ Gemini è™•ç†è½‰éŒ„å…§å®¹"""
    
    # æ§‹å»ºæç¤ºè©
    prompt = f"""è«‹å°‡ä»¥ä¸‹æ¼”è¬›è½‰éŒ„å…§å®¹æ•´ç†æˆè©³ç´°çš„ç­†è¨˜ã€‚

è¦æ±‚ï¼š
1. **ä¸æ˜¯æ‘˜è¦**ï¼Œè€Œæ˜¯å®Œæ•´æ•´ç†æ¼”è¬›è€…çš„å…§å®¹
2. ä¿ç•™æ¼”è¬›è€…çš„æ‰€æœ‰é‡è¦è§€é»ã€æ•¸æ“šã€æ¡ˆä¾‹å’Œç´°ç¯€
3. é€²è¡Œä¿®é£¾æ½¤ç¨¿ï¼Œä¿®æ­£èªéŸ³è½‰éŒ„éŒ¯èª¤ï¼Œä½¿å…§å®¹æ›´å°ˆæ¥­æ˜“è®€
4. ä½¿ç”¨æ¸…æ™°çš„éšå±¤çµæ§‹çµ„ç¹”å…§å®¹
5. å°é‡é»ä½¿ç”¨ **ç²—é«”**ã€*æ–œé«”* æˆ– __åº•ç·š__ æ¨™è¨˜
6. ä¿æŒå°ˆæ¥­è¡“èªçš„æº–ç¢ºæ€§ï¼ˆç‰¹åˆ¥æ˜¯é†«å­¸è¡“èªï¼‰
7. å¦‚æœæœ‰å¤šä½æ¼”è¬›è€…ï¼Œæ˜ç¢ºæ¨™ç¤ºæ¯ä½æ¼”è¬›è€…çš„å…§å®¹
8. ä¿ç•™é‡è¦çš„æ•¸æ“šã€çµ±è¨ˆè³‡æ–™å’Œç ”ç©¶ç™¼ç¾

æœƒè­°æ¨™é¡Œï¼š{session_title}

"""
    
    if agenda_content:
        prompt += f"""
è­°ç¨‹å…§å®¹ï¼š
{agenda_content}

è«‹æ ¹æ“šä¸Šè¿°è­°ç¨‹çš„çµæ§‹ä¾†çµ„ç¹”æ¼”è¬›å…§å®¹ï¼Œè®“ç­†è¨˜çµæ§‹èˆ‡è­°ç¨‹å°æ‡‰ã€‚

"""
    
    prompt += f"""
è½‰éŒ„å…§å®¹ï¼š
{transcription_content[:50000]}  

è«‹ç”Ÿæˆè©³ç´°çš„æ¼”è¬›ç­†è¨˜ï¼ˆä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼‰ã€‚è¨˜ä½ï¼šé€™ä¸æ˜¯æ‘˜è¦ï¼Œè€Œæ˜¯å®Œæ•´çš„æ¼”è¬›å…§å®¹æ•´ç†ï¼Œè¦å„˜å¯èƒ½ä¿ç•™æ¼”è¬›è€…çš„æ‰€æœ‰é‡è¦å…§å®¹ã€‚
"""
    
    try:
        # èª¿ç”¨ Gemini API
        response = model.generate_content(prompt)
        
        if response.text:
            return True, response.text, {
                'prompt_tokens': len(prompt),
                'completion_tokens': len(response.text),
                'model': 'gemini-2.5-pro'
            }
        else:
            return False, "No response from Gemini", {}
            
    except Exception as e:
        return False, str(e), {}


def save_progress(progress_file: str, progress: Dict):
    """ä¿å­˜é€²åº¦"""
    with open(progress_file, 'w', encoding='utf-8') as f:
        json.dump(progress, f, ensure_ascii=False, indent=2)


def load_progress(progress_file: str) -> Dict:
    """è¼‰å…¥é€²åº¦"""
    if os.path.exists(progress_file):
        with open(progress_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {'processed': [], 'failed': [], 'stats': {}}


def main():
    if len(sys.argv) < 3:
        print("ç”¨æ³•: python batch_transcription_notes_v2.py <base_path> <gemini_api_key>")
        sys.exit(1)
    
    base_path = sys.argv[1]
    api_key = sys.argv[2]
    
    print("\nğŸ“ æ‰¹æ¬¡è™•ç†éŸ³é »è½‰éŒ„ç­†è¨˜ v2")
    print("="*60)
    print(f"ä½¿ç”¨æ¨¡å‹: Gemini 2.5 Pro")
    print(f"è™•ç†è·¯å¾‘: {base_path}")
    print("="*60)
    
    # è¨­ç½® Gemini
    model = setup_gemini(api_key)
    
    # æŸ¥æ‰¾æ‰€æœ‰è½‰éŒ„æ–‡ä»¶
    transcription_files = []
    for pattern in ['transcription*.txt', 'transcription*.srt']:
        transcription_files.extend(Path(base_path).rglob(pattern))
    
    # éæ¿¾æ‰éš±è—æ–‡ä»¶å’Œé‡è¤‡çš„ï¼ˆå„ªå…ˆä½¿ç”¨ .txtï¼‰
    transcription_files = [f for f in transcription_files if not f.name.startswith('._')]
    
    # å»é‡ï¼šå¦‚æœåŒæ™‚æœ‰ .txt å’Œ .srtï¼Œåªä¿ç•™ .txt
    unique_files = {}
    for f in transcription_files:
        base_key = str(f.parent) + '/' + f.stem
        if base_key not in unique_files:
            unique_files[base_key] = f
        elif f.suffix == '.txt':  # å„ªå…ˆä½¿ç”¨ .txt
            unique_files[base_key] = f
    
    transcription_files = list(unique_files.values())
    
    print(f"\næ‰¾åˆ° {len(transcription_files)} å€‹ç¨ç‰¹çš„è½‰éŒ„æ–‡ä»¶")
    
    if not transcription_files:
        print("æœªæ‰¾åˆ°ä»»ä½•è½‰éŒ„æ–‡ä»¶")
        return
    
    # è¼‰å…¥é€²åº¦
    progress_file = 'transcription_notes_progress_v2.json'
    progress = load_progress(progress_file)
    
    # é–‹å§‹è™•ç†
    start_time = time.time()
    processed_count = 0
    failed_count = 0
    
    for i, trans_file in enumerate(transcription_files, 1):
        trans_path = str(trans_file)
        
        # æª¢æŸ¥æ˜¯å¦å·²è™•ç†
        if trans_path in progress['processed']:
            print(f"\n[{i}/{len(transcription_files)}] å·²è™•ç†é: {trans_file.name}")
            continue
        
        # ç²å–æœƒè­°æ¨™é¡Œï¼ˆå¾çˆ¶æ–‡ä»¶å¤¾åç¨±ï¼‰
        parent_folder = trans_file.parent
        session_title = parent_folder.name
        
        print(f"\n[{i}/{len(transcription_files)}] è™•ç†: {session_title}")
        print(f"  æ–‡ä»¶: {trans_file.name}")
        
        try:
            # è®€å–è½‰éŒ„å…§å®¹
            transcription_content = read_transcription_file(trans_path)
            
            if not transcription_content or len(transcription_content) < 100:
                print("  âš ï¸  è½‰éŒ„å…§å®¹å¤ªçŸ­ï¼Œè·³é")
                continue
            
            print(f"  è½‰éŒ„é•·åº¦: {len(transcription_content)} å­—ç¬¦")
            
            # æŸ¥æ‰¾è­°ç¨‹æ–‡ä»¶ï¼ˆåŒåçš„å…¶ä»–æ ¼å¼æ–‡ä»¶ï¼‰
            agenda_content = None
            agenda_file = find_agenda_file(str(parent_folder), trans_file.stem)
            if agenda_file:
                print(f"  æ‰¾åˆ°è­°ç¨‹æ–‡ä»¶: {os.path.basename(agenda_file)}")
                agenda_content = extract_agenda_from_file(agenda_file)
                if agenda_content and len(agenda_content) > 50:
                    print(f"  è­°ç¨‹å…§å®¹é•·åº¦: {len(agenda_content)} å­—ç¬¦")
            else:
                print("  æœªæ‰¾åˆ°å°æ‡‰çš„è­°ç¨‹æ–‡ä»¶")
            
            # è™•ç†è½‰éŒ„å…§å®¹
            success, notes_content, info = process_transcription_with_gemini(
                model, 
                transcription_content,
                agenda_content,
                session_title
            )
            
            if success:
                # ä¿å­˜ç­†è¨˜
                output_file = trans_file.with_name(f"{trans_file.stem}_detailed_notes.md")
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(f"# {session_title} - è©³ç´°æ¼”è¬›ç­†è¨˜\n\n")
                    f.write(f"*åŸºæ–¼éŸ³é »è½‰éŒ„æ–‡ä»¶ç”Ÿæˆï¼š{trans_file.name}*\n\n")
                    f.write(f"*ç”Ÿæˆæ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n\n")
                    if agenda_file:
                        f.write(f"*åƒè€ƒè­°ç¨‹ï¼š{os.path.basename(agenda_file)}*\n\n")
                    f.write("---\n\n")
                    f.write(notes_content)
                
                print(f"  âœ… ç­†è¨˜å·²ä¿å­˜: {output_file.name}")
                progress['processed'].append(trans_path)
                processed_count += 1
                
                # æ›´æ–°çµ±è¨ˆ
                if 'total_tokens' not in progress['stats']:
                    progress['stats']['total_tokens'] = 0
                progress['stats']['total_tokens'] += info.get('prompt_tokens', 0) + info.get('completion_tokens', 0)
                
            else:
                print(f"  âŒ è™•ç†å¤±æ•—: {notes_content}")
                progress['failed'].append({
                    'file': trans_path,
                    'error': notes_content,
                    'timestamp': datetime.now().isoformat()
                })
                failed_count += 1
            
            # ä¿å­˜é€²åº¦
            save_progress(progress_file, progress)
            
            # å»¶é²ä»¥éµå®ˆ API é™åˆ¶
            time.sleep(3)  # Gemini 2.5 Pro æœ‰è¼ƒå¯¬é¬†çš„é™åˆ¶
            
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ç”¨æˆ¶ä¸­æ–·ï¼é€²åº¦å·²ä¿å­˜ã€‚")
            save_progress(progress_file, progress)
            break
        except Exception as e:
            print(f"  âŒ éŒ¯èª¤: {str(e)}")
            progress['failed'].append({
                'file': trans_path,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            })
            failed_count += 1
            save_progress(progress_file, progress)
    
    # å®Œæˆçµ±è¨ˆ
    total_time = time.time() - start_time
    print("\n" + "="*60)
    print("ğŸ“Š è™•ç†å®Œæˆçµ±è¨ˆ")
    print("="*60)
    print(f"æœ¬æ¬¡è™•ç†: {processed_count} å€‹æˆåŠŸ, {failed_count} å€‹å¤±æ•—")
    print(f"ç¸½å…±è™•ç†: {len(progress['processed'])} å€‹æ–‡ä»¶")
    print(f"ç¸½ç”¨æ™‚: {total_time/60:.1f} åˆ†é˜")
    
    if processed_count > 0:
        print(f"å¹³å‡è™•ç†æ™‚é–“: {total_time/processed_count:.1f} ç§’/æ–‡ä»¶")
    
    if 'total_tokens' in progress['stats']:
        print(f"ç¸½ Token ä½¿ç”¨: {progress['stats']['total_tokens']:,}")
    
    print(f"\nâœ… æ‰¹æ¬¡è™•ç†å®Œæˆï¼")
    print(f"ç­†è¨˜æ–‡ä»¶å·²ä¿å­˜ç‚º: *_detailed_notes.md")
    print(f"é€²åº¦æ–‡ä»¶: {progress_file}")


if __name__ == "__main__":
    main()