#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
åˆä½µç­†è¨˜æœ€çµ‚å ±å‘Š
"""

import os
import json
from pathlib import Path
from datetime import datetime


def main():
    base_path = "/Volumes/WD_BLACK/åœ‹éš›å¹´æœƒ/ADA2025"
    
    print("\nğŸ“Š æ¼”è¬›ç­†è¨˜èˆ‡æŠ•å½±ç‰‡åˆä½µæœ€çµ‚å ±å‘Š")
    print("="*80)
    print(f"ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80)
    
    # è¼‰å…¥é€²åº¦
    progress_file = 'merge_notes_progress.json'
    if os.path.exists(progress_file):
        with open(progress_file, 'r') as f:
            progress = json.load(f)
    else:
        print("æ‰¾ä¸åˆ°é€²åº¦æ–‡ä»¶")
        return
    
    # æŸ¥æ‰¾ç”Ÿæˆçš„åˆä½µç­†è¨˜
    merged_files = []
    for f in Path(base_path).rglob('*_merged_notes.md'):
        if not f.name.startswith('._'):
            merged_files.append(f)
    
    # çµ±è¨ˆ
    print("\nâœ… è™•ç†å®Œæˆç¸½çµï¼š")
    print(f"  â€¢ æˆåŠŸè™•ç†æ–‡ä»¶å¤¾: {len(progress['processed'])} å€‹")
    print(f"  â€¢ ç”Ÿæˆåˆä½µç­†è¨˜: {len(merged_files)} å€‹")
    print(f"  â€¢ ä½¿ç”¨ Gemini 2.5 Pro tokens: {progress['stats'].get('total_tokens', 0):,}")
    
    # æˆæœ¬ä¼°ç®—
    total_tokens = progress['stats'].get('total_tokens', 0)
    estimated_cost = (total_tokens / 1_000_000) * 7.5
    print(f"  â€¢ ä¼°è¨ˆæˆæœ¬: ${estimated_cost:.2f} USD")
    
    # åˆ—å‡ºæˆåŠŸåˆä½µçš„æœƒè­°
    print(f"\nğŸ“ æˆåŠŸåˆä½µçš„æœƒè­°ï¼ˆ{len(merged_files)} å ´ï¼‰ï¼š")
    folders = sorted(set(f.parent.name for f in merged_files))
    for i, folder in enumerate(folders, 1):
        print(f"  {i:2d}. {folder}")
    
    # æŸ¥æ‰¾åŸå§‹æ–‡ä»¶çµ±è¨ˆ
    notes_count = len(list(Path(base_path).rglob('transcription-*_detailed_notes.md')))
    slides_count = len(list(Path(base_path).rglob('selected_slides_analysis.md')))
    
    print(f"\nğŸ“Š æ–‡ä»¶çµ±è¨ˆï¼š")
    print(f"  â€¢ æ¼”è¬›ç­†è¨˜ç¸½æ•¸: {notes_count} å€‹")
    print(f"  â€¢ æŠ•å½±ç‰‡åˆ†æç¸½æ•¸: {slides_count} å€‹")
    print(f"  â€¢ æˆåŠŸåˆä½µ: {len(merged_files)} å€‹")
    print(f"  â€¢ åˆä½µç‡: {len(merged_files)/min(notes_count, slides_count)*100:.1f}%")
    
    print("\nğŸ’¡ åˆä½µç­†è¨˜ç‰¹é»ï¼š")
    print("  â€¢ ä»¥æ¼”è¬›è€…å…§å®¹ç‚ºä¸»è»¸")
    print("  â€¢ åŠ å…¥æŠ•å½±ç‰‡åƒè€ƒæ¨™è¨˜ (åƒè¦‹ Slide X)")
    print("  â€¢ åº•ç·šæ¨™è¨˜è£œå……èªªæ˜ (__å»¶ä¼¸å…§å®¹__)")
    print("  â€¢ é¿å…é‡è¤‡ï¼Œåªè£œå……æ–°è³‡è¨Š")
    print("  â€¢ å»ºç«‹æ¼”è¬›èˆ‡æŠ•å½±ç‰‡çš„å°æ‡‰é—œä¿‚")
    
    print("\nğŸ“ åˆä½µç­†è¨˜ä½ç½®ï¼š")
    print("  å„æœƒè­°æ–‡ä»¶å¤¾ä¸­çš„ transcription-*_merged_notes.md")
    
    # ä¿å­˜æœ€çµ‚å ±å‘Š
    report = {
        'timestamp': datetime.now().isoformat(),
        'statistics': {
            'folders_processed': len(progress['processed']),
            'merged_notes_generated': len(merged_files),
            'total_tokens': progress['stats'].get('total_tokens', 0),
            'estimated_cost_usd': round(estimated_cost, 2),
            'merge_rate': round(len(merged_files)/min(notes_count, slides_count)*100, 1)
        },
        'successful_merges': [f.parent.name for f in merged_files]
    }
    
    with open('merge_notes_final_report.json', 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“„ è©³ç´°å ±å‘Šå·²ä¿å­˜åˆ°: merge_notes_final_report.json")
    
    # é¡¯ç¤ºç¯„ä¾‹
    if merged_files:
        example = merged_files[0]
        print(f"\nğŸ“ åˆä½µç­†è¨˜ç¯„ä¾‹ï¼š{example.name}")
        with open(example, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read(500)
            print("---")
            print(content)
            print("---")


if __name__ == "__main__":
    main()