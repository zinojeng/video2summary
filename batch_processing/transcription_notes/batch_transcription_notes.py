#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ‰¹æ¬¡è™•ç†éŸ³é »è½‰éŒ„æ–‡ä»¶ï¼Œç”Ÿæˆè©³ç´°ç­†è¨˜
ä½¿ç”¨ Gemini API é€²è¡Œå…§å®¹æ•´ç†å’Œæ½¤ç¨¿
"""

import os
import sys
import json
import time
import re
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
import google.generativeai as genai
from datetime import datetime


def setup_gemini(api_key: str):
    """è¨­ç½® Gemini API"""
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-2.5-pro')
    return model


def read_transcription_file(file_path: str) -> str:
    """è®€å–è½‰éŒ„æ–‡ä»¶"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # å¦‚æœæ˜¯ SRT æ–‡ä»¶ï¼Œå»é™¤æ™‚é–“æˆ³
    if file_path.endswith('.srt'):
        # ç§»é™¤ SRT æ ¼å¼çš„åºè™Ÿå’Œæ™‚é–“æˆ³
        lines = content.split('\n')
        text_lines = []
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            # è·³éåºè™Ÿ
            if line.isdigit():
                i += 1
                # è·³éæ™‚é–“æˆ³
                if i < len(lines) and '-->' in lines[i]:
                    i += 1
                # æ”¶é›†æ–‡æœ¬
                while i < len(lines) and lines[i].strip() != '':
                    text_lines.append(lines[i].strip())
                    i += 1
            i += 1
        content = ' '.join(text_lines)
    
    return content


def find_agenda_files(folder_path: str) -> Optional[str]:
    """æŸ¥æ‰¾è­°ç¨‹æ–‡ä»¶ï¼ˆdocx, rtf, txtï¼‰"""
    folder = Path(folder_path)
    for ext in ['*.docx', '*.rtf', '*.txt']:
        agenda_files = list(folder.glob(ext))
        if agenda_files:
            # å„ªå…ˆé¸æ“‡åŒ…å«æœƒè­°æ¨™é¡Œçš„æ–‡ä»¶
            for f in agenda_files:
                if not f.name.startswith('._') and 'transcription' not in f.name.lower():
                    return str(f)
    return None


def extract_agenda_from_file(file_path: str) -> str:
    """å¾æ–‡ä»¶ä¸­æå–è­°ç¨‹ä¿¡æ¯"""
    try:
        if file_path.endswith('.txt'):
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()[:2000]  # é™åˆ¶é•·åº¦
        elif file_path.endswith('.rtf'):
            # ç°¡å–®æå– RTF ä¸­çš„æ–‡æœ¬
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                # ç§»é™¤ RTF æ§åˆ¶å­—ç¬¦
                text = re.sub(r'\\[a-z]+\d*\s?', '', content)
                text = re.sub(r'[{}]', '', text)
                return text[:2000]
        elif file_path.endswith('.docx'):
            # å¦‚æœæœ‰ python-docx å¯ä»¥ä½¿ç”¨
            try:
                import docx
                doc = docx.Document(file_path)
                text = '\n'.join([para.text for para in doc.paragraphs])
                return text[:2000]
            except:
                return "Agenda file found but cannot read .docx format"
    except Exception as e:
        return f"Error reading agenda: {str(e)}"
    
    return "No agenda content extracted"


def process_transcription_with_gemini(
    model,
    transcription_content: str,
    agenda_content: Optional[str],
    session_title: str
) -> Tuple[bool, str, Dict[str, Any]]:
    """ä½¿ç”¨ Gemini è™•ç†è½‰éŒ„å…§å®¹"""
    
    # æ§‹å»ºæç¤ºè©
    prompt = f"""è«‹å°‡ä»¥ä¸‹æ¼”è¬›è½‰éŒ„å…§å®¹æ•´ç†æˆè©³ç´°çš„ç­†è¨˜ã€‚

è¦æ±‚ï¼š
1. **ä¸æ˜¯æ‘˜è¦**ï¼Œè€Œæ˜¯å®Œæ•´æ•´ç†æ¼”è¬›è€…çš„å…§å®¹
2. ä¿ç•™æ¼”è¬›è€…çš„æ‰€æœ‰é‡è¦è§€é»å’Œç´°ç¯€
3. é€²è¡Œä¿®é£¾æ½¤ç¨¿ï¼Œä½¿å…§å®¹æ›´æ˜“è®€
4. ä½¿ç”¨éšå±¤çµæ§‹çµ„ç¹”å…§å®¹
5. å°é‡é»ä½¿ç”¨ **ç²—é«”**ã€*æ–œé«”* æˆ– __åº•ç·š__ æ¨™è¨˜
6. å¦‚æœæœ‰è­°ç¨‹ï¼Œæ ¹æ“šè­°ç¨‹åˆ†æ®µæ•´ç†
7. ä¿æŒå°ˆæ¥­è¡“èªçš„æº–ç¢ºæ€§
8. ä¿®æ­£æ˜é¡¯çš„èªéŸ³è½‰éŒ„éŒ¯èª¤

æœƒè­°æ¨™é¡Œï¼š{session_title}

"""
    
    if agenda_content:
        prompt += f"""
è­°ç¨‹å…§å®¹ï¼š
{agenda_content}

è«‹æ ¹æ“šä¸Šè¿°è­°ç¨‹ä¾†çµ„ç¹”å…§å®¹çµæ§‹ã€‚

"""
    
    prompt += f"""
è½‰éŒ„å…§å®¹ï¼š
{transcription_content}

è«‹ç”Ÿæˆè©³ç´°çš„æ¼”è¬›ç­†è¨˜ï¼ˆä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼‰ï¼š
"""
    
    try:
        # èª¿ç”¨ Gemini API
        response = model.generate_content(prompt)
        
        if response.text:
            return True, response.text, {
                'prompt_tokens': len(prompt),
                'completion_tokens': len(response.text),
                'model': 'gemini-2.5-pro'
            }
        else:
            return False, "No response from Gemini", {}
            
    except Exception as e:
        return False, str(e), {}


def save_progress(progress_file: str, progress: Dict):
    """ä¿å­˜é€²åº¦"""
    with open(progress_file, 'w', encoding='utf-8') as f:
        json.dump(progress, f, ensure_ascii=False, indent=2)


def load_progress(progress_file: str) -> Dict:
    """è¼‰å…¥é€²åº¦"""
    if os.path.exists(progress_file):
        with open(progress_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {'processed': [], 'failed': [], 'stats': {}}


def main():
    if len(sys.argv) < 3:
        print("ç”¨æ³•: python batch_transcription_notes.py <base_path> <gemini_api_key>")
        sys.exit(1)
    
    base_path = sys.argv[1]
    api_key = sys.argv[2]
    
    print("\nğŸ“ æ‰¹æ¬¡è™•ç†éŸ³é »è½‰éŒ„ç­†è¨˜")
    print("="*60)
    print(f"ä½¿ç”¨æ¨¡å‹: Gemini 2.5 Pro")
    print(f"è™•ç†è·¯å¾‘: {base_path}")
    print("="*60)
    
    # è¨­ç½® Gemini
    model = setup_gemini(api_key)
    
    # æŸ¥æ‰¾æ‰€æœ‰è½‰éŒ„æ–‡ä»¶
    transcription_files = []
    for pattern in ['transcription*.txt', 'transcription*.srt']:
        transcription_files.extend(Path(base_path).rglob(pattern))
    
    # éæ¿¾æ‰éš±è—æ–‡ä»¶
    transcription_files = [f for f in transcription_files if not f.name.startswith('._')]
    
    print(f"\næ‰¾åˆ° {len(transcription_files)} å€‹è½‰éŒ„æ–‡ä»¶")
    
    if not transcription_files:
        print("æœªæ‰¾åˆ°ä»»ä½•è½‰éŒ„æ–‡ä»¶")
        return
    
    # è¼‰å…¥é€²åº¦
    progress_file = 'transcription_notes_progress.json'
    progress = load_progress(progress_file)
    
    # é–‹å§‹è™•ç†
    start_time = time.time()
    processed_count = 0
    failed_count = 0
    
    for i, trans_file in enumerate(transcription_files, 1):
        trans_path = str(trans_file)
        
        # æª¢æŸ¥æ˜¯å¦å·²è™•ç†
        if trans_path in progress['processed']:
            print(f"\n[{i}/{len(transcription_files)}] å·²è™•ç†é: {trans_file.name}")
            continue
        
        # ç²å–æœƒè­°æ¨™é¡Œï¼ˆå¾çˆ¶æ–‡ä»¶å¤¾åç¨±ï¼‰
        parent_folder = trans_file.parent
        session_title = parent_folder.name
        
        print(f"\n[{i}/{len(transcription_files)}] è™•ç†: {session_title}")
        print(f"  æ–‡ä»¶: {trans_file.name}")
        
        try:
            # è®€å–è½‰éŒ„å…§å®¹
            transcription_content = read_transcription_file(trans_path)
            
            if not transcription_content or len(transcription_content) < 100:
                print("  âš ï¸  è½‰éŒ„å…§å®¹å¤ªçŸ­ï¼Œè·³é")
                continue
            
            print(f"  è½‰éŒ„é•·åº¦: {len(transcription_content)} å­—ç¬¦")
            
            # æŸ¥æ‰¾è­°ç¨‹æ–‡ä»¶
            agenda_content = None
            agenda_file = find_agenda_files(str(parent_folder))
            if agenda_file:
                print(f"  æ‰¾åˆ°è­°ç¨‹æ–‡ä»¶: {os.path.basename(agenda_file)}")
                agenda_content = extract_agenda_from_file(agenda_file)
            
            # è™•ç†è½‰éŒ„å…§å®¹
            success, notes_content, info = process_transcription_with_gemini(
                model, 
                transcription_content,
                agenda_content,
                session_title
            )
            
            if success:
                # ä¿å­˜ç­†è¨˜
                output_file = trans_file.with_name(f"{trans_file.stem}_notes.md")
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(f"# {session_title} - æ¼”è¬›ç­†è¨˜\n\n")
                    f.write(f"*åŸºæ–¼éŸ³é »è½‰éŒ„æ–‡ä»¶ç”Ÿæˆï¼š{trans_file.name}*\n\n")
                    f.write(f"*ç”Ÿæˆæ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n\n")
                    f.write("---\n\n")
                    f.write(notes_content)
                
                print(f"  âœ… ç­†è¨˜å·²ä¿å­˜: {output_file.name}")
                progress['processed'].append(trans_path)
                processed_count += 1
                
                # æ›´æ–°çµ±è¨ˆ
                if 'total_tokens' not in progress['stats']:
                    progress['stats']['total_tokens'] = 0
                progress['stats']['total_tokens'] += info.get('prompt_tokens', 0) + info.get('completion_tokens', 0)
                
            else:
                print(f"  âŒ è™•ç†å¤±æ•—: {notes_content}")
                progress['failed'].append({
                    'file': trans_path,
                    'error': notes_content,
                    'timestamp': datetime.now().isoformat()
                })
                failed_count += 1
            
            # ä¿å­˜é€²åº¦
            save_progress(progress_file, progress)
            
            # å»¶é²ä»¥éµå®ˆ API é™åˆ¶
            time.sleep(3)  # Gemini 2.5 Pro æœ‰è¼ƒå¯¬é¬†çš„é™åˆ¶
            
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ç”¨æˆ¶ä¸­æ–·ï¼é€²åº¦å·²ä¿å­˜ã€‚")
            save_progress(progress_file, progress)
            break
        except Exception as e:
            print(f"  âŒ éŒ¯èª¤: {str(e)}")
            progress['failed'].append({
                'file': trans_path,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            })
            failed_count += 1
            save_progress(progress_file, progress)
    
    # å®Œæˆçµ±è¨ˆ
    total_time = time.time() - start_time
    print("\n" + "="*60)
    print("ğŸ“Š è™•ç†å®Œæˆçµ±è¨ˆ")
    print("="*60)
    print(f"æœ¬æ¬¡è™•ç†: {processed_count} å€‹æˆåŠŸ, {failed_count} å€‹å¤±æ•—")
    print(f"ç¸½å…±è™•ç†: {len(progress['processed'])} å€‹æ–‡ä»¶")
    print(f"ç¸½ç”¨æ™‚: {total_time/60:.1f} åˆ†é˜")
    
    if processed_count > 0:
        print(f"å¹³å‡è™•ç†æ™‚é–“: {total_time/processed_count:.1f} ç§’/æ–‡ä»¶")
    
    if 'total_tokens' in progress['stats']:
        print(f"ç¸½ Token ä½¿ç”¨: {progress['stats']['total_tokens']:,}")
    
    print(f"\nâœ… æ‰¹æ¬¡è™•ç†å®Œæˆï¼")
    print(f"ç­†è¨˜æ–‡ä»¶å·²ä¿å­˜ç‚º: *_notes.md")
    print(f"é€²åº¦æ–‡ä»¶: {progress_file}")


if __name__ == "__main__":
    main()